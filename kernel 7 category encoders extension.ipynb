{
  "cells": [
    {
      "metadata": {
        "_uuid": "0b56d6310494c7196d34f174f16bf9c96d805df8"
      },
      "cell_type": "markdown",
      "source": "# Extension of Category Encoders Benchmarking\n## By Jeff Hale\n\nThe python sklearn-compatible *Category Encoders* package provides eleven methods for encoding categorical (oridnal and nominal) data in numerical format for machine learning models as of July 2018 .\n\nWill McGinnis, primary author of the package, benchmarked the first encoders included in the package with three Classification-type data with a Naive Bayes BernouliNB classifier [here](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/). When writing [this guide](https://www.kaggle.com/discdiver/measurement-scales-for-machine-learning/) to explain options for encoding ordinal and nominal data, I tested the newest Category Encoders with a variety of models to try to provide insights as to when to try different encoders. \n\nThere is a good bit of parameter tuning to do. Some model parameters may need different parameters for different encoders due to dimensionality or sparsity. \n\nI ran two of the datasets with nine sklearn classification algorithms, without changing the default perameters. I left out the genetic splicing dataset because the the over 3,000 unique values in two different columns was causing problems with algorithms in my Kaggle Kernel. \n\nMy adaptation of McGinnis's code is below. \n"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import time\nimport gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nimport category_encoders\n\nfrom IPython.display import display, HTML\n\npd.options.display.max_columns = 50\npd.options.display.width = 1000\n\n%matplotlib inline\nplt.style.use('ggplot')\nsns.set(font_scale=1.5)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nnp.random.seed(34)\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# moved loaders.py into this file\n\ndef get_cars_data():\n    \"\"\"Load the cars dataset, split it into X and y, and then call the label encoder to get an integer y column.\n    \n    :return X: predictor columns\n    :type X: pandas.core.frame.DataFrame\n    :return y: prediction column\n    :type y: numpy.ndarray\n    :return mapping: maps string values to ordinal integers\n    :type mapping: list of dictionaries\n    \"\"\"\n\n    df = pd.read_csv('../input/car-names/car.data.txt')\n    X = df.reindex(columns=[x for x in df.columns.values if x != 'class'])  # equivalent to drop \"class\" column\n    y = df.reindex(columns=['class'])\n    print(y['class'].value_counts())\n    y = preprocessing.LabelEncoder().fit_transform(y.values.reshape(-1, ))\n\n    mapping = [\n        {'col': 'buying', 'mapping': [('vhigh', 0), ('high', 1), ('med', 2), ('low', 3)]},\n        {'col': 'maint', 'mapping': [('vhigh', 0), ('high', 1), ('med', 2), ('low', 3)]},\n        {'col': 'doors', 'mapping': [('2', 0), ('3', 1), ('4', 2), ('5more', 3)]},\n        {'col': 'persons', 'mapping': [('2', 0), ('4', 1), ('more', 2)]},\n        {'col': 'lug_boot', 'mapping': [('small', 0), ('med', 1), ('big', 2)]},\n        {'col': 'safety', 'mapping': [('high', 0), ('med', 1), ('low', 2)]},\n    ]\n    \n    return X, y, mapping\n\n\ndef get_mushroom_data():\n    \"\"\"Load the mushroom dataset, split it into X and y, and then call the label encoder to get an integer y column.\"\"\"\n\n    df = pd.read_csv('../input/mushroom-type/agaricus-lepiota.csv')\n    X = df.reindex(columns=[x for x in df.columns.values if x != 'class'])\n    y = df.reindex(columns=['class'])\n    print(y['class'].value_counts())\n    y = preprocessing.LabelEncoder().fit_transform(y.values.reshape(-1, ))\n\n    # this data is truly categorical, with no known concept of ordering\n    mapping = None\n\n    return X, y, mapping\n\n\ndef get_splice_data():\n    \"\"\"Load the splice dataset, split it into X and y, and then call the label encoder to get an integer y column.\"\"\"\n\n    df = pd.read_csv('../input/primate-splicejunction-gene-sequences/splice.csv')\n    X = df.reindex(columns=[x for x in df.columns.values if x != 'class'])\n    X['dna'] = X['dna'].map(lambda x: list(str(x).strip()))\n    for idx in range(60):\n        X['dna_%d' % (idx, )] = X['dna'].map(lambda x: x[idx])\n    del X['dna']\n\n    y = df.reindex(columns=['class'])\n    y = preprocessing.LabelEncoder().fit_transform(y.values.reshape(-1, ))\n\n    # this data is truly categorical, with no known concept of ordering (aka nominal)\n    mapping = None\n\n    return X, y, mapping",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a3e9e3ef09b4b398a2a83ac3f91ba4f641d22ded"
      },
      "cell_type": "code",
      "source": "def score_models(clf, X, y, encoder, runs=1):\n    \"\"\"\n    Takes in a classifier that supports multiclass classification, and X and a y, \n    and returns a cross validation score.\n\n    :param clf: classifier that supports multiclass classification\n    :type clf: sklearn algorithm\n    :param X: X data columns\n    :type X: numpy.ndarray\n    :param y: y data column\n    :type y: numpy.ndarray\n    :param encoder: encoder to use for running the model\n    :type encoder: type\n    :param runs: default = 1, number of times to fit_transform and run the model\n    :type runs: int\n    \n    :return float(np.mean(scores)): mean of cross val scores\n    :return float(np.std(scores)): standard deviation of cross val scores\n    :return scores: list of scores\n    :return X_test.shape[1]: number of features\n    \"\"\"\n\n    scores = []\n\n    X_test = None\n    for _ in range(runs):\n        X_test = encoder().fit_transform(X, y)\n        scores.append(cross_val_score(clf, X_test, y, n_jobs=1, cv=5))\n        gc.collect()\n\n    scores = [y for z in [x for x in scores] for y in z]\n    return float(np.mean(scores)), float(np.std(scores)), scores, X_test.shape[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c14790a76452388ca24be10f7f7fe2cba130b5cb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def main(loader, name, models):\n    \"\"\"\n    Load a dataset and score with a list of models using different encodings.\n    \n    :param loader: function name of dataset loading and x,y splitting function to call\n    :type loader: string\n    :param name:  model name to output\n    :type name: string\n    :param models: which machine learning models to use\n    :type models: dictionary with keys models names strings and sklearn model class values\n    \n    :return: rankings info for each encoder\n    :return type: dataframe\n    \"\"\"\n    \n    scores = []                               # list for encoder score info\n    raw_scores_ds = {}                        # dict for holding raw scores\n    model_name = []                           # list of dataframes of results per model type\n    mods = [*models.values()]                 # get models and model names \n    mod_names = [*models.keys()]\n    counter = 0                                # counter to print element in mod_names\n    ranked = pd.DataFrame()                    # df used to rank each encoder and then take a mean ranking\n    X, y, mapping = loader()                   # load the dataset\n    \n    for clf in mods:                           # iterate through each model\n        encoders = category_encoders.__all__   # use each encoding method available\n        for encoder_name in encoders:\n            encoder = getattr(category_encoders, encoder_name)\n            start_time = time.time()\n            score, stds, raw_scores, dim = score_models(clf, X, y, encoder)\n            scores.append( [encoder_name, score, stds, dim, time.time() - start_time, mod_names[counter], name,])\n            raw_scores_ds[encoder_name] = raw_scores\n            model_name.append(clf)\n            \n        re = pd.DataFrame(scores, columns=['Encoding', 'Avg. Score', 'Score StDev', 'Dimensionality',  'Elapsed Time', \"Model\",  'Dataset',])\n        re = re.round(decimals=2)\n        re['ranking'] = re['Avg. Score'].rank(ascending=False)\n        display(HTML(re.sort_values(by=['Model', 'Avg. Score'], ascending = True).to_html()))\n        \n        ranked = ranked.append(re) \n        \n        # plot the scores\n        raw = pd.DataFrame.from_dict(raw_scores_ds)\n        fig, ax = plt.subplots(figsize = (10, 8))\n        sns.boxplot(ax = ax, data=raw, palette=\"colorblind\")\n        plt.title('Scores for {mod} Encodings on Dataset {ds}'.format(mod = mod_names[counter], ds = name))\n        plt.ylabel('Score (higher better)')\n        plt.xticks(rotation=90)\n        plt.grid()\n        plt.tight_layout()\n        plt.show()\n        \n        scores = []\n        counter += 1  \n        \n    rank_thus_far = ranked.groupby('Encoding')['ranking'].agg(['mean', 'std', 'min', 'max', 'count'])       \n    return rank_thus_far",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c54e447413046a15767e2ae37b4ad88b60830c4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# models to test\nmodel_dict =  {\"LR\": LogisticRegression(),\n                #  MLPClassifier(), \n                #  KNeighborsClassifier(),\n                #  SVC(),\n                #  RandomForestClassifier(),\n                #  GaussianNB(),\n                #  GaussianProcessClassifier(), \n                #  DecisionTreeClassifier(), \n                #  AdaBoostClassifier(), \n                \"QDA\": QuadraticDiscriminantAnalysis()\n                }\n\n# main(get_splice_data, 'Splice', mods)       # commented out because splice is throwing a ValueError when running. \n\n# ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n# There are no NaNs in the dataset. ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7e8072d211df064c36631b57c8f9194970a1a269"
      },
      "cell_type": "markdown",
      "source": "## Run models and encoders on Cars dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a6e692677dd6a8c3d5920d6d7e714058c96c704",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "cars_df = main(get_cars_data, 'Cars', model_dict) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "963a171c67941f35fadea7de3c6f975aedbc7c5b"
      },
      "cell_type": "markdown",
      "source": "Note that the cars data set is quite imbalanced, with the vast majority of observations listed as unacceptable.\nQDA is warning us that the variables are correlated. And quite a few encoders perform very poorly on QDA."
    },
    {
      "metadata": {
        "_uuid": "f964b92b8e86a0e5e7b94f21620ba5188d86b856"
      },
      "cell_type": "markdown",
      "source": "## Cars dataset ranking"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a016d795df8c6d0670162af02bae5cadc9de7c8d"
      },
      "cell_type": "code",
      "source": "display(HTML(car_ranks.sort_values(by=['mean', 'std'], ascending = True).to_html())) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cab32169959ba7527cb4422fe86f26b2208a47a7"
      },
      "cell_type": "markdown",
      "source": "## Run models and encoders on Mushroom dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4163fc8bff3d4e9152a785fe38bf4d3be4804ab",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "mushroom_df = main(get_mushroom_data, 'Mushroom', model_dict)  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bde1376438c0fe906f1d82a47823049391888fc6"
      },
      "cell_type": "markdown",
      "source": "Note that the Mushroom dataset's  binary outcomes, \"edible\" and \"poisonous\", are fairly balanced. QDA performs much better with all the encoders."
    },
    {
      "metadata": {
        "_uuid": "976a9de3e1269883e21fad5b0cfb3b31403996f6"
      },
      "cell_type": "markdown",
      "source": "## Mushroom dataset ranking"
    },
    {
      "metadata": {
        "_uuid": "f4216238cfa980b11f3b80b08ccc97249797bb61"
      },
      "cell_type": "markdown",
      "source": "##  Rank the models"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4d269ee992061d316b641c9e3e79deae7b262400"
      },
      "cell_type": "code",
      "source": "display(HTML(mushroom_ranks.sort_values(by=['mean', 'std'], ascending = True).to_html())) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8de437a32c3b98fdad9a74cbfafeceef9597cfa7"
      },
      "cell_type": "markdown",
      "source": "## Questions\n\nIs there too much variation? How large are changes in QDA if using different random seeds?  Maybe  large because much collinearity in features.\n\nShould we use a classifiction metric like roc/auc instead of accuracy? Accuracy is simple, but also not always what you want - because the unbalanced dataset isn't binary classification, not as much of an issue there. The mushroom dataset is binary but balanced, so not a big concern there either."
    },
    {
      "metadata": {
        "_uuid": "135980f22e4f99fa24986476c38830a92080bbe5"
      },
      "cell_type": "markdown",
      "source": "## Takeaways\n\nThere is a fair bit of variation for different encoding schemes over different trials, with different models, and across the data sets. We really need to look at regression and more data sets.\n\nThe hashing encoder performs consistently poorly.  Is just a poor fit with the data sets?\n\nBackward difference and ordinal do poorly with encoding on the mushroom data set, which makes sense as those all depend upon meaningful  ordering of the categories in the nominal data.\n\nOrdinal does great with the Mushroom dataset.\n\nOne-hot doesn't do terribly. With more cardinality, it could have more problems.\n\nAdaBoost had a super tough time with this, particulary with the Binary and BaseN encoding. It did better with Hashing, but still poorly. It performed decently with ordinal, backward difference, helmert, and polynomial on the car. Not sure about polynomial, but the other encoders do have real ordinal data encoded, so those should work better in cars than in mushrooms."
    },
    {
      "metadata": {
        "_uuid": "bb658d97c315ed4ed23fa0d8ecb62c1e2b7ff46a"
      },
      "cell_type": "markdown",
      "source": "## Future Projects\n\nGrid search CV for parameter selection to make it a more real-world comparision of models\n\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}